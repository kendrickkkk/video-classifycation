{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir dataset\n",
    "%cd dataset\n",
    "!gdown 1N93rb_uFqKRZ9naX8CXShFt5RJHOmjZH\n",
    "!unzip -q rwf-2000.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from transformers import VideoMAEConfig, VideoMAEForVideoClassification\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n",
    "LOGGER = logging.getLogger(\"Torch-Cls\")\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=2, image_size=224, num_frames=15):\n",
    "        super(Model, self).__init__()\n",
    "        cfg = VideoMAEConfig()\n",
    "        cfg.num_classes = num_classes\n",
    "        cfg.image_size = image_size\n",
    "        cfg.num_frames = num_frames\n",
    "\n",
    "        self.vivit = VideoMAEForVideoClassification.from_pretrained(\n",
    "            \"MCG-NJU/videomae-base\",\n",
    "            config=cfg,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x_3d):\n",
    "        # (bs, C, T, H, W) -> (bs, T, C, H, W)\n",
    "        x_3d = x_3d.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "        out = self.vivit(x_3d)\n",
    "\n",
    "        return out.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'fc_norm.bias', 'fc_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 86228738 parameters\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Example of how to use the model\n",
    "model = Model(num_classes=2, num_frames=15)\n",
    "\n",
    "# Check param\n",
    "param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model has {param} parameters\")\n",
    "\n",
    "# Test the model with a random input (batch_size, channels, frames, height, width)\n",
    "inputs = torch.rand(1, 3, 15, 224, 224)\n",
    "\n",
    "output = model(inputs)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, inputs, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, phase=\"train\", transform=None, n_frames=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the videos (each video as a subdirectory of frames).\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            n_frames (int, optional): Number of frames to sample from each video, uniformly. If None, use all frames.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.n_frames = n_frames\n",
    "        self.phase = phase\n",
    "        self.videos, self.labels = self._load_videos()\n",
    "\n",
    "    def _load_videos(self):\n",
    "        videos, labels = [], []\n",
    "        class_id = 0\n",
    "\n",
    "        video_folders = os.listdir(os.path.join(self.root_dir, self.phase))\n",
    "\n",
    "        for folder in video_folders:\n",
    "            video_paths = os.listdir(os.path.join(self.root_dir, self.phase, folder))\n",
    "\n",
    "            for video_path in video_paths:\n",
    "                video_folder = os.path.join(\n",
    "                    self.root_dir, self.phase, folder, video_path\n",
    "                )\n",
    "                frames = sorted(\n",
    "                    (os.path.join(video_folder, f) for f in os.listdir(video_folder)),\n",
    "                    key=lambda f: int(\n",
    "                        \"\".join(filter(str.isdigit, os.path.basename(f)))\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                if self.n_frames:\n",
    "                    frames = self._uniform_sample(frames, self.n_frames)\n",
    "\n",
    "                videos.append(frames)\n",
    "                labels.append(class_id)\n",
    "\n",
    "            class_id += 1\n",
    "\n",
    "        return videos, labels\n",
    "\n",
    "    def _uniform_sample(self, frames, n_frames):\n",
    "        \"\"\"\n",
    "        Helper method to uniformly sample n_frames from the frames list.\n",
    "        \"\"\"\n",
    "        stride = max(1, len(frames) // n_frames)\n",
    "        sampled = [frames[i] for i in range(0, len(frames), stride)]\n",
    "        return sampled[:n_frames]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_frames = self.videos[idx]\n",
    "        label = self.labels[idx]\n",
    "        images = []\n",
    "        for frame_path in video_frames:\n",
    "            image = Image.open(frame_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            images.append(image)\n",
    "\n",
    "        # Stack images along new dimension (sequence length)\n",
    "        data = torch.stack(images, dim=0)\n",
    "\n",
    "        # Rearrange to have the shape (C, T, H, W)\n",
    "        data = data.permute(1, 0, 2, 3)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cpus: 4\n",
      "torch.Size([4, 3, 15, 224, 224]) tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "MAX_LEN = 15\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = VideoDataset(\n",
    "    root_dir=\"./dataset/rwf-2000\", phase=\"train\", transform=transform, n_frames=MAX_LEN\n",
    ")\n",
    "\n",
    "val_dataset = VideoDataset(\n",
    "    root_dir=\"./dataset/rwf-2000\", phase=\"val\", transform=transform, n_frames=MAX_LEN\n",
    ")\n",
    "\n",
    "# Count number of cpus\n",
    "cpus = 4\n",
    "print(f\"Number of cpus: {cpus}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, num_workers=cpus, shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, num_workers=cpus, shuffle=False\n",
    ")\n",
    "\n",
    "# test\n",
    "for data, label in train_loader:\n",
    "    print(data.shape, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorstr(*input):\n",
    "    *args, string = input if len(input) > 1 else (\"blue\", \"bold\", input[0])\n",
    "    colors = {\n",
    "        \"black\": \"\\033[30m\",  # basic colors\n",
    "        \"red\": \"\\033[31m\",\n",
    "        \"green\": \"\\033[32m\",\n",
    "        \"yellow\": \"\\033[33m\",\n",
    "        \"blue\": \"\\033[34m\",\n",
    "        \"magenta\": \"\\033[35m\",\n",
    "        \"cyan\": \"\\033[36m\",\n",
    "        \"white\": \"\\033[37m\",\n",
    "        \"bright_black\": \"\\033[90m\",  # bright colors\n",
    "        \"bright_red\": \"\\033[91m\",\n",
    "        \"bright_green\": \"\\033[92m\",\n",
    "        \"bright_yellow\": \"\\033[93m\",\n",
    "        \"bright_blue\": \"\\033[94m\",\n",
    "        \"bright_magenta\": \"\\033[95m\",\n",
    "        \"bright_cyan\": \"\\033[96m\",\n",
    "        \"bright_white\": \"\\033[97m\",\n",
    "        \"end\": \"\\033[0m\",  # misc\n",
    "        \"bold\": \"\\033[1m\",\n",
    "        \"underline\": \"\\033[4m\",\n",
    "    }\n",
    "    return \"\".join(colors[x] for x in args) + f\"{string}\" + colors[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs=25, device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to train the model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The neural network model to train.\n",
    "    - train_loader: DataLoader for the training set.\n",
    "    - val_loader: DataLoader for the validation set.\n",
    "    - criterion: The loss function.\n",
    "    - optimizer: The optimization algorithm.\n",
    "    - num_epochs: Number of epochs to train for.\n",
    "    - device: The device to run the training on, 'cuda' or 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "    - model: The trained model.\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"lr\": [],\n",
    "    }\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    # Send the model to the specified device\n",
    "    model.to(device)\n",
    "\n",
    "    # Loop over the dataset multiple times\n",
    "    for epoch in range(num_epochs):\n",
    "        LOGGER.info(colorstr(f\"Epoch {epoch}/{num_epochs-1}:\"))\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                LOGGER.info(\n",
    "                    colorstr(\"bright_yellow\", \"bold\", \"\\n%20s\" + \"%15s\" * 3)\n",
    "                    % (\"Training:\", \"gpu_mem\", \"loss\", \"acc\")\n",
    "                )\n",
    "                model.train()\n",
    "            else:\n",
    "                LOGGER.info(\n",
    "                    colorstr(\"bright_green\", \"bold\", \"\\n%20s\" + \"%15s\" * 3)\n",
    "                    % (\"Validation:\", \"gpu_mem\", \"loss\", \"acc\")\n",
    "                )\n",
    "                model.eval()\n",
    "\n",
    "            running_items = 0\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Use the appropriate data loader\n",
    "            data_loader = train_loader if phase == \"train\" else val_loader\n",
    "\n",
    "            _phase = tqdm(\n",
    "                data_loader,\n",
    "                total=len(data_loader),\n",
    "                bar_format=\"{desc} {percentage:>7.0f}%|{bar:10}{r_bar}{bar:-10b}\",\n",
    "                unit=\"batch\",\n",
    "            )\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in _phase:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_items += outputs.size(0)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / running_items\n",
    "                epoch_acc = running_corrects / running_items\n",
    "\n",
    "                mem = f\"{torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0:.3g}GB\"\n",
    "                desc = (\"%35s\" + \"%15.6g\" * 2) % (\n",
    "                    mem,\n",
    "                    epoch_loss,\n",
    "                    epoch_acc,\n",
    "                )\n",
    "                _phase.set_description_str(desc)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                history[\"train_loss\"].append(epoch_loss)\n",
    "                history[\"train_acc\"].append(epoch_acc.item())\n",
    "            else:\n",
    "                history[\"val_loss\"].append(epoch_loss)\n",
    "                history[\"val_acc\"].append(epoch_acc.item())\n",
    "                if epoch_acc > best_val_acc:\n",
    "                    best_val_acc = epoch_acc\n",
    "                    history[\"best_epoch\"] = epoch\n",
    "\n",
    "                print(f\"Best val Acc: {best_val_acc:4f}\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    history[\"INFO\"] = (\n",
    "        \"Training complete in {:.0f}h {:.0f}m {:.0f}s with {} epochs - Best val Acc: {:4f}\".format(\n",
    "            time_elapsed // 3600,\n",
    "            time_elapsed % 3600 // 60,\n",
    "            time_elapsed % 60,\n",
    "            num_epochs,\n",
    "            best_val_acc,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'fc_norm.bias', 'fc_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mEpoch 0/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.456184       0.784375     100%|██████████| 400/400 [03:06<00:00,  2.15batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.292487         0.8775     100%|██████████| 100/100 [00:17<00:00,  5.76batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 1/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.877500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB       0.244186         0.9075     100%|██████████| 400/400 [03:06<00:00,  2.14batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.250078         0.8825     100%|██████████| 100/100 [00:17<00:00,  5.75batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 2/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.882500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB       0.106329          0.965     100%|██████████| 400/400 [03:06<00:00,  2.14batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.272148         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.76batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 3/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.892500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB      0.0364751       0.989375     100%|██████████| 400/400 [03:06<00:00,  2.14batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.624832         0.8725     100%|██████████| 100/100 [00:17<00:00,  5.75batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 4/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.892500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB       0.043204        0.98625     100%|██████████| 400/400 [03:06<00:00,  2.14batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.301304         0.9125     100%|██████████| 100/100 [00:17<00:00,  5.76batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 5/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB     0.00605501       0.999375     100%|██████████| 400/400 [03:07<00:00,  2.13batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.405028         0.9075     100%|██████████| 100/100 [00:17<00:00,  5.73batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 6/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB      0.0116211          0.995     100%|██████████| 400/400 [03:10<00:00,  2.10batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.538667          0.885     100%|██████████| 100/100 [00:17<00:00,  5.69batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 7/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB      0.0583342           0.98     100%|██████████| 400/400 [03:10<00:00,  2.10batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.318377         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.68batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 8/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB      0.0185161        0.99375     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.380317         0.8975     100%|██████████| 100/100 [00:17<00:00,  5.68batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 9/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB     0.00816649         0.9975     100%|██████████| 400/400 [03:08<00:00,  2.12batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.403177          0.895     100%|██████████| 100/100 [00:17<00:00,  5.67batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 10/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    0.000291947              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.427212            0.9     100%|██████████| 100/100 [00:17<00:00,  5.68batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 11/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    0.000112331              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.454203         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.70batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 12/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB     7.3014e-05              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.474956         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.69batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 13/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    5.21658e-05              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.493288         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.70batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 14/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    3.86533e-05              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.511179         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.67batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 15/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    2.93449e-05              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.527656         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.69batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 16/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    2.26502e-05              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.544163         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.71batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 17/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    1.76881e-05              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.560112         0.8925     100%|██████████| 100/100 [00:17<00:00,  5.71batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 18/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    1.39488e-05              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.575794          0.895     100%|██████████| 100/100 [00:17<00:00,  5.68batch/s]\n",
      "\u001b[34m\u001b[1mEpoch 19/19:\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "           Training:        gpu_mem           loss            acc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             10.1GB    1.10843e-05              1     100%|██████████| 400/400 [03:09<00:00,  2.11batch/s]\n",
      "\u001b[92m\u001b[1m\n",
      "         Validation:        gpu_mem           loss            acc\u001b[0m\n",
      "                             10.1GB       0.591482          0.895     100%|██████████| 100/100 [00:17<00:00,  5.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.912500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage (assuming you have defined your criterion and optimizer):\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model(num_classes=2, num_frames=15)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "trained_model = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs=20, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duc_open_sora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
